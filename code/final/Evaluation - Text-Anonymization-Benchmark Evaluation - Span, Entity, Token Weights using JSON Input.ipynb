{"cells":[{"cell_type":"markdown","metadata":{"id":"nlAihGVkxpuJ"},"source":["# Pre-requisites"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26975,"status":"ok","timestamp":1733713051087,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"},"user_tz":480},"id":"luPna3YsyMTR","outputId":"a4a0ab80-73db-4797-b0a9-1c2e068356bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_md')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["!python -m spacy download en_core_web_md --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hXNkhu55xszh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733713062537,"user_tz":480,"elapsed":11452,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}},"outputId":"0ccf6bc1-d379-46ae-b161-dbef2aef4195"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install intervaltree --quiet"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52523,"status":"ok","timestamp":1733713115059,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"},"user_tz":480},"id":"-XMDp3NRxlDW","outputId":"43c221af-8467-4850-87db-d4534ad5bcd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import json, re, sys, abc, argparse, math\n","import numpy as np\n","from typing import Any, Dict, List, Tuple\n","from dataclasses import dataclass\n","from tqdm import tqdm\n","import pandas\n","import spacy\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import intervaltree"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wJOzW-DhxPAS","executionInfo":{"status":"ok","timestamp":1733713115429,"user_tz":480,"elapsed":372,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}}},"outputs":[],"source":["# POS tags, tokens or characters that can be ignored from the recall scores\n","# (because they do not carry much semantic content, and there are discrepancies\n","# on whether to include them in the annotated spans or not)\n","POS_TO_IGNORE = {\"ADP\", \"PART\", \"CCONJ\", \"DET\"}\n","TOKENS_TO_IGNORE = {\"mr\", \"mrs\", \"ms\", \"no\", \"nr\", \"about\"}\n","CHARACTERS_TO_IGNORE = \" ,.-;:/&()[]–'\\\" ’“”\"\n","\n","@dataclass\n","class MaskedDocument:\n","    \"\"\"Represents a document in which some text spans are masked, each span\n","    being expressed by their (start, end) character boundaries\"\"\"\n","\n","    doc_id: str\n","    masked_spans : List[Tuple[int, int]]\n","\n","    def get_masked_offsets(self):\n","        \"\"\"Returns the character offsets that are masked\"\"\"\n","        if not hasattr(self, \"masked_offsets\"):\n","            self.masked_offsets = {i for start, end in self.masked_spans\n","                                   for i in range(start, end)}\n","        return self.masked_offsets\n","\n","\n","class TokenWeighting:\n","    \"\"\"Abstract class for token weighting schemes (used to compute the precision)\"\"\"\n","\n","    @abc.abstractmethod\n","    def get_weights(self, text:str, text_spans:List[Tuple[int,int]]):\n","        \"\"\"Given a text and a list of text spans, returns a list of numeric weights\n","        (of same length as the list of spans) representing the information content\n","        conveyed by each span.\n","\n","        A weight close to 0 represents a span with low information content (i.e. which\n","        can be easily predicted from the remaining context), while a weight close to 1\n","        represents a high information content (which is difficult to predict from the\n","        context)\"\"\"\n","\n","        return\n","\n","@dataclass\n","class AnnotatedEntity:\n","    \"\"\"Represents an entity annotated in a document, with a unique identifier,\n","    a list of mentions (character-level spans in the document), whether it\n","    needs to be masked, and whether it corresponds to a direct identifier\"\"\"\n","\n","    entity_id: str\n","    mentions: List[Tuple[int, int]]\n","    need_masking: bool\n","    is_direct: bool\n","    entity_type: str\n","    mention_level_masking: List[bool]\n","\n","    def __post_init__(self):\n","        if self.is_direct and not self.need_masking:\n","            raise RuntimeError(\"Direct identifiers must always be masked\")\n","\n","    @property\n","    def mentions_to_mask(self):\n","        return [mention for i, mention in enumerate(self.mentions)\n","                if self.mention_level_masking[i]]\n","\n","class GoldCorpus:\n","    \"\"\"Representation of a gold standard corpus for text anonymisation, extracted from a\n","    JSON file. See annotation guidelines for the TAB corpus for details. \"\"\"\n","\n","    def __init__(self, gold_standard_json_file:str, spacy_model = \"en_core_web_md\"):\n","\n","        # Loading the spacy model\n","        nlp = spacy.load(spacy_model)\n","\n","        # documents indexed by identifier\n","        self.documents = {}\n","\n","        # Train/dev/test splits\n","        self.splits = {}\n","\n","        fd = open(gold_standard_json_file, encoding=\"utf-8\")\n","        annotated_docs = json.load(fd)\n","        fd.close()\n","        print(\"Reading annotated corpus with %i documents\"%len(annotated_docs))\n","\n","        if type(annotated_docs)!=list:\n","            raise RuntimeError(\"JSON file should be a list of annotated documents\")\n","\n","        for ann_doc in annotated_docs:\n","\n","            for key in [\"doc_id\", \"text\", \"annotations\", \"dataset_type\"]:\n","                if key not in ann_doc:\n","                    raise RuntimeError(\"Annotated document is not well formed: missing variable %s\"%key)\n","\n","            # Parsing the document with spacy\n","            spacy_doc = nlp(ann_doc[\"text\"])\n","\n","            # Creating the actual document (identifier, text and annotations)\n","            new_doc = GoldDocument(ann_doc[\"doc_id\"], ann_doc[\"text\"],\n","                                   ann_doc[\"annotations\"], spacy_doc)\n","            self.documents[ann_doc[\"doc_id\"]] = new_doc\n","\n","            # Adding it to the list for the specified split (train, dev or test)\n","            data_split = ann_doc[\"dataset_type\"]\n","            self.splits[data_split] = self.splits.get(data_split, []) + [ann_doc[\"doc_id\"]]\n","\n","\n","\n","\n","    def get_entity_recall(self, masked_docs:List[MaskedDocument], include_direct=True,\n","                       include_quasi=True):\n","        \"\"\"Returns the entity-level recall of the masked spans when compared to the gold\n","        standard annotations. Arguments:\n","        - masked_docs: documents together with spans masked by the system\n","        - include_direct: whether to include direct identifiers in the metric\n","        - include_quasi: whether to include quasi identifiers in the metric\n","\n","        The recall is computed at the level of entities and not mentions, and we consider\n","        an entity to be masked only if all of its mentions are masked.\n","\n","        If annotations from several annotators are available for a given document, the recall\n","        corresponds to a micro-average over the annotators. \"\"\"\n","\n","        nb_masked_entities = 0\n","        nb_entities = 0\n","\n","   #     print(\"Computing entity-level recall on %i documents\"%len(masked_docs),\n","   #           (\"(include direct identifiers: %s, include quasi identifiers: %s)\"\n","   #           %(include_direct, include_quasi)))\n","\n","        for doc in masked_docs:\n","\n","            gold_doc = self.documents[doc.doc_id]\n","\n","            entities_to_mask = gold_doc.get_entities_to_mask(include_direct, include_quasi)\n","            masked_entities = [entity for entity in entities_to_mask if gold_doc.is_masked(doc, entity)]\n","            nb_masked_entities += len(masked_entities)\n","            nb_entities +=  len(entities_to_mask)\n","        try:\n","            return nb_masked_entities / nb_entities\n","        except ZeroDivisionError:\n","            return 0\n","\n","\n","    def get_recall(self, masked_docs:List[MaskedDocument], include_direct=True,\n","                       include_quasi=True, token_level:bool=True):\n","        \"\"\"Returns the mention or token-level recall of the masked spans when compared\n","        to the gold standard annotations.\n","\n","        Arguments:\n","        - masked_docs: documents together with spans masked by the system\n","        - include_direct: whether to include direct identifiers in the metric\n","        - include_quasi: whether to include quasi identifiers in the metric\n","        - token_level: whether to compute the recall at the level of tokens or mentions\n","\n","        If annotations from several annotators are available for a given document, the recall\n","        corresponds to a micro-average over the annotators. \"\"\"\n","\n","        nb_masked_by_type, nb_by_type = self._get_mask_counts(masked_docs, include_direct,\n","                                                                  include_quasi, token_level)\n","\n","        nb_masked_elements = sum(nb_masked_by_type.values())\n","        nb_elements = sum(nb_by_type.values())\n","\n","        try:\n","            return nb_masked_elements / nb_elements\n","        except ZeroDivisionError:\n","            return 0\n","\n","    def get_recall_per_entity_type(self, masked_docs:List[MaskedDocument], include_direct=True,\n","                                   include_quasi=True, token_level:bool=True):\n","        \"\"\"Returns the mention or token-level recall of the masked spans when compared\n","        to the gold standard annotations, and factored by entity type.\n","\n","        Arguments:\n","        - masked_docs: documents together with spans masked by the system\n","        - include_direct: whether to include direct identifiers in the metric\n","        - include_quasi: whether to include quasi identifiers in the metric\n","        - token_level: whether to compute the recall at the level of tokens or mentions\n","\n","        If annotations from several annotators are available for a given document, the recall\n","        corresponds to a micro-average over the annotators. \"\"\"\n","\n","        nb_masked_by_type, nb_by_type = self._get_mask_counts(masked_docs, include_direct,\n","                                                                  include_quasi, token_level)\n","\n","        return {ent_type:nb_masked_by_type[ent_type]/nb_by_type[ent_type]\n","                for ent_type in nb_by_type}\n","\n","\n","    def _get_mask_counts(self, masked_docs:List[MaskedDocument], include_direct=True,\n","                                   include_quasi=True, token_level:bool=True):\n","\n","        nb_masked_elements_by_type = {}\n","        nb_elements_by_type = {}\n","\n","        for doc in masked_docs:\n","\n","            gold_doc = self.documents[doc.doc_id]\n","            for entity in gold_doc.get_entities_to_mask(include_direct, include_quasi):\n","\n","                if entity.entity_type not in nb_elements_by_type:\n","                    nb_elements_by_type[entity.entity_type] = 0\n","                    nb_masked_elements_by_type[entity.entity_type] = 0\n","\n","                spans = list(entity.mentions)\n","                if token_level:\n","                    spans = [(start, end) for mention_start, mention_end in spans\n","                             for start, end in gold_doc.split_by_tokens(mention_start, mention_end)]\n","\n","                for start, end in spans:\n","                    if gold_doc.is_mention_masked(doc, start, end):\n","                        nb_masked_elements_by_type[entity.entity_type] += 1\n","                    nb_elements_by_type[entity.entity_type] += 1\n","\n","        return nb_masked_elements_by_type, nb_elements_by_type\n","\n","\n","    def show_false_negatives(self, masked_docs:List[MaskedDocument], include_direct=True,\n","                       include_quasi=True, include_partial_match=True, include_no_match=True):\n","        \"\"\"Prints out the false negatives (mentions that should have been masked but\n","        haven't) to facilitate error analysis.\n","        If include_partial_match is set to True, we include mentions which are partially\n","        masked. If include_no_match is set to True, we include mentions that are not\n","        masked at all.\n","        \"\"\"\n","\n","        if not include_partial_match and not include_no_match:\n","            raise RuntimeError(\"Must include some match to display\")\n","\n","        for doc in masked_docs:\n","\n","            gold_doc = self.documents[doc.doc_id]\n","            masked_text_chars = list(gold_doc.text)\n","            for span_start, span_end in doc.masked_spans:\n","                masked_text_chars[span_start:span_end] = [\"*\"]*(span_end-span_start)\n","            masked_text = \"\".join(masked_text_chars)\n","\n","            for entity in gold_doc.get_entities_to_mask(include_direct, include_quasi):\n","\n","                for mention_start, mention_end in entity.mentions:\n","                    if not gold_doc.is_mention_masked(doc, mention_start, mention_end):\n","\n","                        is_partial_match = \"*\" in masked_text[mention_start:mention_end]\n","                        if is_partial_match and not include_partial_match:\n","                            continue\n","                        elif not is_partial_match and not include_no_match:\n","                            continue\n","\n","                        print(\"Mention:\", gold_doc.text[mention_start:mention_end],\n","                            \"(doc_id %s, span [%i-%i])\"%\n","                            (gold_doc.doc_id, mention_start, mention_end))\n","                        context = masked_text[max(0, mention_start-30): mention_end+30]\n","                        context = re.sub(\"\\s\\s+\", \" \", context.replace(\"\\n\", \" \"), re.DOTALL)\n","                        print(\"Context:\", context)\n","                        print(\"=============\")\n","\n","\n","\n","    def get_precision(self, masked_docs:List[MaskedDocument], token_weighting:TokenWeighting,\n","                      token_level:bool=True):\n","        \"\"\"Returns the weighted, token-level precision of the masked spans when compared\n","        to the gold standard annotations. Arguments:\n","        - masked_docs: documents together with spans masked by the system\n","        - token_weighting: mechanism for weighting the information content of each token\n","\n","        If token_level is set to true, the precision is computed at the level of tokens,\n","        otherwise the precision is at the mention-level. The masked spans/tokens are weighted\n","        by their information content, given the provided weighting scheme. If annotations from\n","        several annotators are available for a given document, the precision corresponds to a\n","        micro-average over the annotators.\"\"\"\n","\n","        weighted_true_positives = 0.0\n","        weighted_system_masks = 0.0\n","\n","        for doc in tqdm(masked_docs):\n","            gold_doc = self.documents[doc.doc_id]\n","\n","            # We extract the list of spans (token- or mention-level)\n","            system_masks = []\n","            for start, end in doc.masked_spans:\n","                if token_level:\n","                    system_masks += list(gold_doc.split_by_tokens(start, end))\n","                else:\n","                    system_masks += [(start,end)]\n","\n","            # We compute the weights (information content) of each mask\n","            weights = token_weighting.get_weights(gold_doc.text, system_masks)\n","\n","            # We store the number of annotators in the gold standard document\n","            nb_annotators = len(set(entity.annotator for entity in gold_doc.entities.values()))\n","\n","            for (start, end), weight in zip(system_masks, weights):\n","\n","                # We extract the annotators that have also masked this token/span\n","                annotators = gold_doc.get_annotators_for_span(start, end)\n","\n","                # And update the (weighted) counts\n","                weighted_true_positives += (len(annotators) * weight)\n","                weighted_system_masks += (nb_annotators * weight)\n","        try:\n","            return weighted_true_positives / weighted_system_masks\n","        except ZeroDivisionError:\n","            return 0\n","\n","\n","\n","class GoldDocument:\n","    \"\"\"Representation of an annotated document\"\"\"\n","\n","    def __init__(self, doc_id:str, text:str, annotations:Dict[str,List],\n","                 spacy_doc: spacy.tokens.Doc):\n","        \"\"\"Creates a new annotated document with an identifier, a text content, and\n","        a set of annotations (see guidelines)\"\"\"\n","\n","        # The (unique) document identifier, its text and the spacy document\n","        self.doc_id = doc_id\n","        self.text = text\n","        self.spacy_doc = spacy_doc\n","\n","        # Annotated entities (indexed by id)\n","        self.entities = {}\n","\n","        for annotator, ann_by_person in annotations.items():\n","\n","            if ann_by_person is not None:\n","              if \"entity_mentions\" not in ann_by_person:\n","                  raise RuntimeError(\"Annotations must include entity_mentions\")\n","\n","              for entity in self._get_entities_from_mentions(ann_by_person[\"entity_mentions\"]):\n","\n","                  # We require each entity_id to be specific for each annotator\n","                  if entity.entity_id in self.entities:\n","                      raise RuntimeError(\"Entity ID %s already used by another annotator\"%entity.entity_id)\n","\n","                  entity.annotator = annotator\n","                  entity.doc_id = doc_id\n","                  self.entities[entity.entity_id] = entity\n","\n","\n","    def _get_entities_from_mentions(self, entity_mentions):\n","        \"\"\"Returns a set of entities based on the annotated mentions\"\"\"\n","\n","        entities = {}\n","\n","        for mention in entity_mentions:\n","\n","            for key in [\"entity_id\", \"identifier_type\", \"start_offset\", \"end_offset\"]:\n","                if key not in mention:\n","                    raise RuntimeError(\"Unspecified key in entity mention: \" + key)\n","\n","            entity_id = mention[\"entity_id\"]\n","            start = mention[\"start_offset\"]\n","            end = mention[\"end_offset\"]\n","\n","            if start < 0 or end > len(self.text) or start >= end:\n","                raise RuntimeError(\"Invalid character offsets: [%i-%i]\"%(start, end))\n","\n","            if mention[\"identifier_type\"] not in [\"DIRECT\", \"QUASI\", \"NO_MASK\"]:\n","                raise RuntimeError(\"Unspecified or invalid identifier type: %s\"%(mention[\"identifier_type\"]))\n","\n","            need_masking = mention[\"identifier_type\"] in [\"DIRECT\", \"QUASI\"]\n","            is_direct = mention[\"identifier_type\"]==\"DIRECT\"\n","\n","\n","            # We check whether the entity is already defined\n","            if entity_id in entities:\n","\n","                # If yes, we simply add a new mention\n","                current_entity = entities[entity_id]\n","                current_entity.mentions.append((start, end))\n","                current_entity.mention_level_masking.append(need_masking)\n","\n","            # Otherwise, we create a new entity with one single mention\n","            else:\n","                new_entity = AnnotatedEntity(entity_id, [(start, end)], need_masking, is_direct,\n","                                             mention[\"entity_type\"], [need_masking])\n","                entities[entity_id] = new_entity\n","\n","        for entity in entities.values():\n","            if set(entity.mention_level_masking) != {entity.need_masking}:\n","                entity.need_masking = True\n","    #            print(\"Warning: inconsistent masking of entity %s: %s\"\n","    #                  %(entity.entity_id, str(entity.mention_level_masking)))\n","\n","        return list(entities.values())\n","\n","\n","    def is_masked(self, masked_doc:MaskedDocument, entity: AnnotatedEntity):\n","        \"\"\"Given a document with a set of masked text spans, determines whether entity\n","        is fully masked (which means that all its mentions are masked)\"\"\"\n","\n","        for incr, (mention_start, mention_end) in enumerate(entity.mentions):\n","\n","            if self.is_mention_masked(masked_doc, mention_start, mention_end):\n","                continue\n","\n","            # The masking is sometimes inconsistent for the same entity,\n","            # so we verify that the mention does need masking\n","            elif entity.mention_level_masking[incr]:\n","                return False\n","        return True\n","\n","\n","    def is_mention_masked(self, masked_doc:MaskedDocument, mention_start:int, mention_end:int):\n","        \"\"\"Given a document with a set of masked text spans and a particular mention span,\n","        determine whether the mention is fully masked (taking into account special\n","        characters or tokens to skip)\"\"\"\n","\n","        mention_to_mask = self.text[mention_start:mention_end].lower()\n","\n","        # Computes the character offsets that must be masked\n","        offsets_to_mask = set(range(mention_start, mention_end))\n","\n","        # We build the set of character offsets that are not covered\n","        non_covered_offsets = offsets_to_mask - masked_doc.get_masked_offsets()\n","\n","        # If we have not covered everything, we also make sure punctuations\n","        # spaces, titles, etc. are ignored\n","        if len(non_covered_offsets) > 0:\n","            span = self.spacy_doc.char_span(mention_start, mention_end, alignment_mode = \"expand\")\n","            for token in span:\n","                if token.pos_ in POS_TO_IGNORE or token.lower_ in TOKENS_TO_IGNORE:\n","                    non_covered_offsets -= set(range(token.idx, token.idx+len(token)))\n","        for i in list(non_covered_offsets):\n","            if self.text[i] in set(CHARACTERS_TO_IGNORE):\n","                non_covered_offsets.remove(i)\n","\n","        # If that set is empty, we consider the mention as properly masked\n","        return len(non_covered_offsets) == 0\n","\n","\n","    def get_entities_to_mask(self,  include_direct=True, include_quasi=True):\n","        \"\"\"Return entities that should be masked, and satisfy the constraints\n","        specified as arguments\"\"\"\n","\n","        to_mask = []\n","        for entity in self.entities.values():\n","\n","            # We only consider entities that need masking and are the right type\n","            if not entity.need_masking:\n","                continue\n","            elif entity.is_direct and not include_direct:\n","                continue\n","            elif not entity.is_direct and not include_quasi:\n","                continue\n","            to_mask.append(entity)\n","\n","        return to_mask\n","\n","\n","    def get_annotators_for_span(self, start_token: int, end_token: int):\n","        \"\"\"Given a text span (typically for a token), determines which annotators\n","        have also decided to mask it. Concretely, the method returns a (possibly\n","        empty) set of annotators names that have masked that span.\"\"\"\n","\n","\n","        # We compute an interval tree for fast retrieval\n","        if not hasattr(self, \"masked_spans\"):\n","            self.masked_spans = intervaltree.IntervalTree()\n","            for entity in self.entities.values():\n","                if entity.need_masking:\n","                    for i, (start, end) in enumerate(entity.mentions):\n","                        if entity.mention_level_masking[i]:\n","                            self.masked_spans[start:end] = entity.annotator\n","\n","        annotators = set()\n","        for mention_start, mention_end, annotator in self.masked_spans[start_token:end_token]:\n","\n","            # We require that the span is fully covered by the annotator\n","            if mention_start <=start_token and mention_end >= end_token:\n","                annotators.add(annotator)\n","\n","        return annotators\n","\n","\n","    def split_by_tokens(self, start: int, end: int):\n","        \"\"\"Generates the (start, end) boundaries of each token included in this span\"\"\"\n","\n","        for match in re.finditer(\"\\w+\", self.text[start:end]):\n","            start_token = start + match.start(0)\n","            end_token = start + match.end(0)\n","            yield start_token, end_token\n","\n","\n","\n","class UniformTokenWeighting(TokenWeighting):\n","    \"\"\"Uniform weighting (all tokens assigned to a weight of 1.0)\"\"\"\n","    def get_weights(self, text:str, text_spans:List[Tuple[int,int]]):\n","        return [1.0] * len(text_spans)\n","\n","\n","class BertTokenWeighting(TokenWeighting):\n","    \"\"\"Token weighting based on a BERT language model. The weighting mechanism\n","    runs the BERT model on a text in which the provided spans are masked. The\n","    weight of each token is then defined as 1-(probability of the actual token value).\n","\n","    In other words, a token that is difficult to predict will have a high\n","    information content, and therefore a high weight, whereas a token which can\n","    be predicted from its content will received a low weight. \"\"\"\n","\n","    def __init__(self, max_segment_size = 100):\n","        \"\"\"Initialises the BERT tokenizers and masked language model\"\"\"\n","\n","        from transformers import BertTokenizerFast, BertForMaskedLM\n","        self.tokeniser = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","        import torch\n","        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","        self.model = self.model.to(self.device)\n","\n","        self.max_segment_size = max_segment_size\n","\n","\n","    def get_weights(self, text:str, text_spans:List[Tuple[int,int]]):\n","        \"\"\"Returns a list of numeric weights between 0 and 1, where each value\n","        corresponds to 1 - (probability of predicting the value of the text span\n","        according to the BERT model).\n","\n","        If the span corresponds to several BERT tokens, the probability is the\n","        product of the probabilities for each token.\"\"\"\n","\n","        import torch\n","\n","        # STEP 1: we tokenise the text\n","        bert_tokens = self.tokeniser(text, return_offsets_mapping=True)\n","        input_ids = bert_tokens[\"input_ids\"]\n","        input_ids_copy = np.array(input_ids)\n","\n","        # STEP 2: we record the mapping between spans and BERT tokens\n","        bert_token_spans = bert_tokens[\"offset_mapping\"]\n","        tokens_by_span = self._get_tokens_by_span(bert_token_spans, text_spans)\n","\n","        # STEP 3: we mask the tokens that we wish to predict\n","        attention_mask = bert_tokens[\"attention_mask\"]\n","        for token_indices in tokens_by_span.values():\n","            for token_idx in token_indices:\n","                attention_mask[token_idx] = 0\n","                input_ids[token_idx] = self.tokeniser.mask_token_id\n","\n","        # STEP 4: we run the masked language model\n","        logits = self._get_model_predictions(input_ids, attention_mask)\n","        unnorm_probs = torch.exp(logits)\n","        probs = unnorm_probs / torch.sum(unnorm_probs, axis=1)[:,None]\n","\n","        # We are only interested in the probs for the actual token values\n","        probs_actual = probs[torch.arange(len(input_ids)), input_ids_copy]\n","        probs_actual = probs_actual.detach().cpu().numpy()\n","\n","        # STEP 5: we compute the weights from those predictions\n","        weights = []\n","        for (span_start, span_end) in text_spans:\n","\n","            # If the span does not include any actual token, skip\n","            if not tokens_by_span[(span_start, span_end)]:\n","                weights.append(0)\n","                continue\n","\n","            # if the span has several tokens, we take the minimum prob\n","            prob = np.min([probs_actual[token_idx] for token_idx in\n","                           tokens_by_span[(span_start, span_end)]])\n","\n","            # We finally define the weight as -log(p)\n","            weights.append(-np.log(prob))\n","\n","        return weights\n","\n","    def _get_tokens_by_span(self, bert_token_spans, text_spans):\n","        \"\"\"Given two lists of spans (one with the spans of the BERT tokens, and one with\n","        the text spans to weight), returns a dictionary where each text span is associated\n","        with the indices of the BERT tokens it corresponds to.\"\"\"\n","\n","        # We create an interval tree to facilitate the mapping\n","        text_spans_tree = intervaltree.IntervalTree()\n","        for start, end in text_spans:\n","            text_spans_tree[start:end] = True\n","\n","        # We create the actual mapping between spans and tokens\n","        tokens_by_span = {span:[] for span in text_spans}\n","        for token_idx, (start, end) in enumerate(bert_token_spans):\n","            for span_start, span_end, _ in text_spans_tree[start:end]:\n","                tokens_by_span[(span_start, span_end)].append(token_idx)\n","\n","        # And control that everything is correct\n","        for span_start, span_end in text_spans:\n","            if len(tokens_by_span[(span_start, span_end)])==0 :\n","                print(\"Warning: span (%i,%i) without any token\"%(span_start, span_end))\n","        return tokens_by_span\n","\n","\n","    def _get_model_predictions(self, input_ids, attention_mask):\n","        \"\"\"Given tokenised input identifiers and an associated attention mask (where the\n","        tokens to predict have a mask value set to 0), runs the BERT language and returns\n","        the (unnormalised) prediction scores for each token.\n","\n","        If the input length is longer than max_segment size, we split the document in\n","        small segments, and then concatenate the model predictions for each segment.\"\"\"\n","\n","        import torch\n","        nb_tokens = len(input_ids)\n","\n","        input_ids = torch.tensor(input_ids)[None,:].to(self.device)\n","        attention_mask = torch.tensor(attention_mask)[None,:].to(self.device)\n","\n","        # If the number of tokens is too large, we split in segments\n","        if nb_tokens > self.max_segment_size:\n","            nb_segments = math.ceil(nb_tokens/self.max_segment_size)\n","\n","            # Split the input_ids (and add padding if necessary)\n","            split_pos = [self.max_segment_size * (i + 1) for i in range(nb_segments - 1)]\n","            input_ids_splits = torch.tensor_split(input_ids[0], split_pos)\n","\n","            input_ids = torch.nn.utils.rnn.pad_sequence(input_ids_splits, batch_first=True)\n","\n","            # Split the attention masks\n","            attention_mask_splits = torch.tensor_split(attention_mask[0], split_pos)\n","            attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask_splits, batch_first=True)\n","\n","        # Run the model on the tokenised inputs + attention mask\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        # And get the resulting prediction scores\n","        scores = outputs.logits\n","\n","        # If the batch contains several segments, concatenate the result\n","        if len(scores) > 1:\n","            scores = torch.vstack([scores[i] for i in range(len(scores))])\n","            scores = scores[:nb_tokens]\n","        else:\n","            scores = scores[0]\n","\n","        return scores\n","\n","\n","def get_masked_docs_from_file(masked_output_file:str):\n","    \"\"\"Given a file path for a JSON file containing the spans to be masked for\n","    each document, returns a list of MaskedDocument objects\"\"\"\n","\n","    fd = open(masked_output_file)\n","    masked_output_docs = json.load(fd)\n","    fd.close()\n","\n","    if type(masked_output_docs)!= dict:\n","        raise RuntimeError(\"%s must contain a mapping between document identifiers\"%masked_output_file\n","                           + \" and lists of masked spans in this document\")\n","\n","    masked_docs = []\n","    for doc_id, doc_data in masked_output_docs.items():\n","        # Verify the doc_data contains the expected structure\n","        if \"doc_id\" not in doc_data or \"masked_spans\" not in doc_data:\n","            raise RuntimeError(f\"Document data for {doc_id} must contain 'doc_id' and 'masked_spans' fields.\")\n","\n","        # Retrieve and validate masked_spans\n","        masked_spans = doc_data[\"masked_spans\"]\n","        if not isinstance(masked_spans, list):\n","            raise RuntimeError(\"Masked spans for the document must be a list of (start, end) pairs\")\n","\n","        # Convert each list pair to a tuple\n","        masked_spans_as_tuples = [(start, end) for start, end in masked_spans]\n","\n","        # Create the MaskedDocument with the tupled masked spans\n","        doc = MaskedDocument(doc_id, masked_spans_as_tuples)\n","        masked_docs.append(doc)\n","\n","    return masked_docs\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UA1W6CVLwylc","executionInfo":{"status":"ok","timestamp":1733713115430,"user_tz":480,"elapsed":3,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}}},"outputs":[],"source":["def compute_evaluation_metrics(gold_standard_file, masked_output_files, token_weighting=\"uniform\", only_docs=None, verbose=False):\n","    \"\"\"\n","    Computes evaluation metrics for text anonymization.\n","\n","    Parameters:\n","    - gold_standard_file (str): Path to the JSON file containing the gold standard annotations.\n","    - masked_output_files (list): List of paths to JSON files with actual spans masked by the system.\n","    - token_weighting (str): Token weighting scheme, either 'uniform' or 'bert' (default: 'uniform').\n","    - only_docs (list, optional): List of document identifiers for focused evaluation (default: None).\n","    - verbose (bool): Flag to provide detailed evaluation results (default: False).\n","    \"\"\"\n","    gold_corpus = GoldCorpus(gold_standard_file)\n","\n","    for masked_output_file in masked_output_files:\n","        print(\"=========\")\n","        masked_docs = get_masked_docs_from_file(masked_output_file)\n","\n","        if only_docs:\n","            masked_docs = [doc for doc in masked_docs if doc.doc_id in only_docs]\n","\n","        for masked_doc in masked_docs:\n","            if masked_doc.doc_id not in gold_corpus.documents:\n","                raise RuntimeError(f\"Document {masked_doc.doc_id} not present in gold corpus\")\n","\n","        if verbose:\n","            gold_corpus.show_false_negatives(masked_docs, True, True)\n","\n","        print(f\"Computing evaluation metrics for {masked_output_file} ({len(masked_docs)} documents)\")\n","\n","        token_recall = gold_corpus.get_recall(masked_docs, True, True, True)\n","        token_recall_by_type = gold_corpus.get_recall_per_entity_type(masked_docs, True, True, True)\n","        mention_recall = gold_corpus.get_recall(masked_docs, True, True, True)\n","        recall_direct_entities = gold_corpus.get_entity_recall(masked_docs, True, True)\n","        recall_quasi_entities = gold_corpus.get_entity_recall(masked_docs, True, True)\n","        token_precision = gold_corpus.get_precision(masked_docs, UniformTokenWeighting())\n","        mention_precision = gold_corpus.get_precision(masked_docs, UniformTokenWeighting(), True)\n","\n","        print(f\"==> Token-level recall on all identifiers: {token_recall:.3f}\")\n","        print(\"==> Token-level recall on all identifiers, factored by type:\")\n","        for ent_type, token_recall_for_ent_type in token_recall_by_type.items():\n","            print(f\"\\t{ent_type}:{token_recall_for_ent_type:.3f}\")\n","        print(f\"==> Mention-level recall on all identifiers: {mention_recall:.3f}\")\n","        print(f\"==> Entity-level recall on direct identifiers: {recall_direct_entities:.3f}\")\n","        print(f\"==> Entity-level recall on quasi identifiers: {recall_quasi_entities:.3f}\")\n","        print(f\"==> Uniform token-level precision on all identifiers: {token_precision:.3f}\")\n","        print(f\"==> Uniform mention-level precision on all identifiers: {mention_precision:.3f}\")\n","\n","        weighting_scheme = UniformTokenWeighting() if token_weighting == \"uniform\" else BertTokenWeighting()\n","\n","        if not isinstance(weighting_scheme, UniformTokenWeighting):\n","            print(f\"Weighting scheme: {token_weighting}\")\n","            weighted_token_precision = gold_corpus.get_precision(masked_docs, weighting_scheme)\n","            weighted_mention_precision = gold_corpus.get_precision(masked_docs, weighting_scheme, False)\n","            print(f\"==> Weighted, token-level precision on all identifiers: {weighted_token_precision:.3f}\")\n","            print(f\"==> Weighted, mention-level precision on all identifiers: {weighted_mention_precision:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"wGhYBnj7xTp-"},"source":["Run Evaluation"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FxIwcC450OjM","executionInfo":{"status":"ok","timestamp":1733713115430,"user_tz":480,"elapsed":2,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}}},"outputs":[],"source":["# full, test dataset select data slicing of original json\n","# global variables\n","model_name = 'longformer_concat' # update to select the right path\n","task = 'mask'\n","size = 'mini'\n","split = 'train'"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"09LZzFWfzR94","executionInfo":{"status":"ok","timestamp":1733713115430,"user_tz":480,"elapsed":2,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}}},"outputs":[],"source":["path = '/content/drive/MyDrive/266 - Natural Language Processing/Final Project/'"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Qv_e1cI60BWv","executionInfo":{"status":"ok","timestamp":1733713115430,"user_tz":480,"elapsed":2,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}}},"outputs":[],"source":["gold_standard_file_path = f'{path}data/tab/echr_{split}_{size}_{task}_filtered.json'\n","masked_output_files_path = f'{path}data/tab/echr_{model_name}_{split}_{size}_{task}_masked_spans.json'\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"nUbRoeXMynNV","executionInfo":{"status":"ok","timestamp":1733713115430,"user_tz":480,"elapsed":2,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}}},"outputs":[],"source":["#gold_standard_file_path = path + '/echr_train_filtered.json'\n","#masked_output_files_path = path + '/train_reconstructed_texts_with_ner_tags_minimal.json'"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SeLmC6ecxVL9","executionInfo":{"status":"ok","timestamp":1733713159973,"user_tz":480,"elapsed":44545,"user":{"displayName":"Derrick Chan-Sew","userId":"03940237157169511489"}},"outputId":"75f26395-16ee-4866-b491-be21385abefd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading annotated corpus with 64 documents\n","=========\n","Mention: Kingdom of Spain (doc_id 001-100686, span [76-92])\n","Context: on (no. ********) against the Kingdom of Spain lodged with the Court under A\n","=============\n","Mention: Spain (doc_id 001-100686, span [10242-10247])\n","Context: , ** ********* has no ties in Spain and could leave the country a\n","=============\n","Mention: Spain (doc_id 001-100686, span [13590-13595])\n","Context: ack of any particular ties in Spain. It referred in that regard t\n","=============\n","Mention: Spain (doc_id 001-100686, span [14948-14953])\n","Context: plicant] supply an address in Spain; (b) that he report every day\n","=============\n","Mention: Spain (doc_id 001-100686, span [17482-17487])\n","Context: e fact that he has no ties in Spain. These circumstances led the \n","=============\n","Mention: Spain (doc_id 001-100686, span [18013-18018])\n","Context:  he has no ties whatsoever in Spain. It follows that bail was fix\n","=============\n","Mention: Spain (doc_id 001-100686, span [18436-18441])\n","Context:  which he had been subject in Spain. The applicant is therefore r\n","=============\n","Mention: Kingdom of Spain (doc_id 001-58010, span [306-322])\n","Context: on (no. ********) against the Kingdom of Spain lodged with the Commission un\n","=============\n","Mention: Spain (doc_id 001-58010, span [553-558])\n","Context: nd to the declaration whereby Spain recognised the compulsory jur\n","=============\n","Mention: Spain (doc_id 001-58010, span [8742-8747])\n","Context: ******, his re-extradition to Spain could not be guaranteed. On \n","=============\n","Mention: two years, six months and twenty-nine days (doc_id 001-58010, span [14339-14381])\n","Context: pplicant had spent a total of two years* *** ****** *** *********** **** under the different orders fo\n","=============\n","Mention: Minister of Agriculture and Country Development (doc_id 001-90246, span [4284-4331])\n","Context: d both decisions given by the Minister of Agriculture and Country Development. As no decision had been giv\n","=============\n","Mention: Minister of Agriculture and Country Development (doc_id 001-90246, span [4422-4469])\n","Context: the applicant lodged with the Minister of Agriculture and Country Development an inactivity complaint and, \n","=============\n","Mention: Minister of Agriculture and Country Development (doc_id 001-90246, span [4605-4652])\n","Context:  Court. On ** ***** **** the Minister of Agriculture and Country Development stayed the proceedings. The a\n","=============\n","Mention: Minister of Agriculture and Country Development (doc_id 001-90246, span [5186-5233])\n","Context: ayed. On * ******** **** the Minister of Agriculture and Country Development gave a decision declaring tha\n","=============\n","Mention: Minister of Agriculture and Country Development (doc_id 001-90246, span [5585-5632])\n","Context: inactivity on the part of the Minister of Agriculture and Country Development. In her complaint, she allege\n","=============\n","Mention: Republic of Poland (doc_id 001-114097, span [75-93])\n","Context: ion (no. *******) against the Republic of Poland lodged with the Court under A\n","=============\n","Mention: Polish (doc_id 001-114097, span [235-241])\n","Context: edoms (“the Convention”) by a Polish national, ** ****** ****** **\n","=============\n","Mention: Polish (doc_id 001-114097, span [401-407])\n","Context: yer practising in Warsaw. The Polish ********** (“the Government”)\n","=============\n","Mention: Polish Government (doc_id 001-114097, span [401-418])\n","Context: yer practising in Warsaw. The Polish ********** (“the Government”) were repre\n","=============\n","Mention: Warsaw (doc_id 001-114097, span [389-395])\n","Context: *****, a lawyer practising in Warsaw. The Polish ********** (“the \n","=============\n","Mention: Meetings and Demonstration Marches Act (doc_id 001-98909, span [5493-5531])\n","Context: plicant, for violation of the Meetings and Demonstration Marches Act. In her defence submissions b\n","=============\n","Mention: Court of Cassation (doc_id 001-59861, span [3676-3694])\n","Context: ed to it. On * **** **** the Court of Cassation quashed the applicant’s convi\n","=============\n","Mention: Landesgericht (doc_id 001-99863, span [3193-3206])\n","Context: l. The ***** ******** ***** (Landesgericht) quashed the decision, orderi\n","=============\n","Mention: Republic of Poland (doc_id 001-82913, span [75-93])\n","Context: ion (no ********) against the Republic of Poland lodged with the Court under A\n","=============\n","Mention: Polish (doc_id 001-82913, span [315-321])\n","Context: cant”), on ** **** ****. The Polish Government (“the Government”)\n","=============\n","Mention: Polish (doc_id 001-82913, span [315-321])\n","Context: cant”), on ** **** ****. The Polish Government (“the Government”)\n","=============\n","Mention: Article 187 of the Turkish Civil Code (doc_id 001-126133, span [1714-1751])\n","Context: est on the ground that, under Article 187 of the Turkish Civil Code, married women had to bear th\n","=============\n","Mention: Saughton Prison (doc_id 001-57446, span [6813-6828])\n","Context: ere was on traditional lines, Saughton Prison would be more beneficial to *\n","=============\n","Mention: vegetarian diet (doc_id 001-57446, span [8716-8731])\n","Context: gs to supplement his (mainly) vegetarian diet by buying oatmeal cakes as th\n","=============\n","Mention: Borgarting High Court (doc_id 001-81994, span [896-917])\n","Context:  impartial hearing before the Borgarting High Court, whose judgment of ** ***** *\n","=============\n","Mention: High Court (doc_id 001-81994, span [4716-4726])\n","Context: risonment on this ground. The High Court found it correct to assess wh\n","=============\n","Mention: High Court (doc_id 001-81994, span [5209-5219])\n","Context: icion has been fulfilled. The High Court does not find it necessary to\n","=============\n","Mention: High Court (doc_id 001-81994, span [5949-5959])\n","Context:  statements and evidence. The High Court bases its judgment, as in the\n","=============\n","Mention: High Court (doc_id 001-81994, span [6506-6516])\n","Context: r of their own motion. In the High Court's opinion, there are no groun\n","=============\n","Mention: High Court (doc_id 001-81994, span [6782-6792])\n","Context: le 172 should take place, the High Court refers to the extensive discu\n","=============\n","Mention: High Court (doc_id 001-81994, span [7471-7481])\n","Context: wo ***** ******* milieus. The High Court adds, as a factor when assess\n","=============\n","Mention: High Court (doc_id 001-81994, span [7906-7916])\n","Context: of an overall assessment, the High Court has found that the law enforc\n","=============\n","Mention: High Court (doc_id 001-81994, span [8571-8581])\n","Context:  to any different result. The High Court has also considered decisions\n","=============\n","Mention: High Court (doc_id 001-81994, span [8900-8910])\n","Context:  remand period is outside the High Court's control. The regime he is n\n","=============\n","Mention: High Court (doc_id 001-81994, span [8993-9003])\n","Context: to be of no importance to the High Court's assessment.” C. Appeal aga\n","=============\n","Mention: High Court (doc_id 001-81994, span [9071-9081])\n","Context:  City Court's judgment to the High Court The first, second and third \n","=============\n","Mention: High Court (doc_id 001-81994, span [9138-9148])\n","Context: rd applicants appealed to the High Court against the City Court's asse\n","=============\n","Mention: High Court (doc_id 001-81994, span [9704-9714])\n","Context: gainst the sentence which the High Court dismissed by a separate decis\n","=============\n","Mention: High Court (doc_id 001-81994, span [9818-9828])\n","Context: rought by the applicants, the High Court held an oral hearing ******* \n","=============\n","Mention: High Court (doc_id 001-81994, span [9893-9903])\n","Context: ****** *** ** ***** ****. The High Court was sitting with a jury of 11\n","=============\n","Mention: High Court (doc_id 001-81994, span [10568-10578])\n","Context: s I and III. Thereafter, the High Court, composed of the three profes\n","=============\n","Mention: High Court (doc_id 001-81994, span [11287-11297])\n","Context: the Supreme Court against the High Court procedure and the sentences. \n","=============\n","Mention: High Court (doc_id 001-81994, span [11443-11453])\n","Context:  impartial hearing before the High Court. Firstly, they argued that J\n","=============\n","Mention: High Court (doc_id 001-81994, span [11513-11523])\n","Context: udge G. had taken part in the High Court decision of * **** **** rejec\n","=============\n","Mention: High Court (doc_id 001-81994, span [11793-11803])\n","Context: de of Criminal Procedure, the High Court had applied a special ground \n","=============\n","Mention: High Court (doc_id 001-81994, span [12634-12644])\n","Context: on the list of witnesses. The High Court had then discharged the jury \n","=============\n","Mention: High Court (doc_id 001-81994, span [13185-13195])\n","Context: deal with the allegation that High Court judge, Judge G., was ********\n","=============\n","Mention: High Court (doc_id 001-81994, span [13336-13346])\n","Context: edure for criminal cases in a High Court that sits with a jury are bas\n","=============\n","Mention: High Court (doc_id 001-81994, span [13527-13537])\n","Context: eedings are determined by the High Court's three professional judges. \n","=============\n","Mention: High Court (doc_id 001-81994, span [14814-14824])\n","Context: s to the presiding judge in a High Court case involving a jury. The fi\n","=============\n","Mention: High Court (doc_id 001-81994, span [15790-15800])\n","Context: *, the presiding judge of the High Court was, with dissenting votes, a\n","=============\n","Mention: High Court (doc_id 001-81994, span [16271-16281])\n","Context: at the presiding judge of the High Court, but at one of the other two \n","=============\n","Mention: High Court (doc_id 001-81994, span [16727-16737])\n","Context: ther professional judges in a High Court that is convened with a jury \n","=============\n","Mention: High Court (doc_id 001-81994, span [17980-17990])\n","Context:  is thus that Judge G. of the High Court was not ************. (22) I \n","=============\n","Mention: High Court (doc_id 001-81994, span [18903-18913])\n","Context: licence number. (24) When the High Court's presiding judge discussed t\n","=============\n","Mention: High Court (doc_id 001-81994, span [19590-19600])\n","Context:  matter was made known to the High Court when it convened on ** ******\n","=============\n","Mention: High Court (doc_id 001-81994, span [19782-19792])\n","Context: nity to make a statement. The High Court thereafter ordered that W. wa\n","=============\n","Mention: High Court (doc_id 001-81994, span [20382-20392])\n","Context: ire jury is disqualified. The High Court finds that such special circu\n","=============\n","Mention: High Court (doc_id 001-81994, span [20750-20760])\n","Context: al in this case. However, the High Court does not find that the jury m\n","=============\n","Mention: High Court (doc_id 001-81994, span [21327-21337])\n","Context: embers. (27) I agree with the High Court that W. was prejudiced. The q\n","=============\n","Mention: High Court (doc_id 001-81994, span [22003-22013])\n","Context: to the Supreme Court that the High Court has, in its reasons for regar\n","=============\n","Mention: City Court (doc_id 001-81994, span [1729-1739])\n","Context: A. Criminal conviction by the City Court On ** ***** **** the applica\n","=============\n","Mention: City Court (doc_id 001-81994, span [4368-4378])\n","Context: cision of ** **** **** by the City Court to prolong his provisional de\n","=============\n","Mention: City Court (doc_id 001-81994, span [4467-4477])\n","Context: d the following reasons: “The City Court has ordered detention of [the\n","=============\n","Mention: City Court (doc_id 001-81994, span [5025-5035])\n","Context:  this issue. According to the City Court's convicting judgment, the ba\n","=============\n","Mention: City Court (doc_id 001-81994, span [7021-7031])\n","Context: ction with the arrest and the City Court proceedings. It appears from \n","=============\n","Mention: City Court (doc_id 001-81994, span [7355-7365])\n","Context: to great sums was caused. The City Court based its ruling on the fact \n","=============\n","Mention: City Court (doc_id 001-81994, span [9042-9052])\n","Context: ment.” C. Appeal against the City Court's judgment to the High Court \n","=============\n","Mention: City Court (doc_id 001-81994, span [9161-9171])\n","Context: to the High Court against the City Court's assessment of facts concern\n","=============\n","Mention: City Court (doc_id 001-81994, span [11598-11608])\n","Context: against a prolongation by the City Court of the fourth applicant's pro\n","=============\n","Mention: City Court (doc_id 001-81994, span [11669-11679])\n","Context: isional detention. Unlike the City Court, which had applied the ordina\n","=============\n","Mention: explosion (doc_id 001-81994, span [20623-20632])\n","Context:  connection to the day of the explosion. Her observations are of such\n","=============\n","Mention: disqualified (doc_id 001-81994, span [20364-20376])\n","Context: tated that the entire jury is disqualified. The High Court finds that su\n","=============\n","Mention: disqualified (doc_id 001-81994, span [20934-20946])\n","Context: jury members so that they are disqualified. It must be assumed that the \n","=============\n","Mention: disqualified (doc_id 001-81994, span [22909-22921])\n","Context: ot be regarded as having been disqualified to serve as a result of jury \n","=============\n","Mention: 10 July 1997 (doc_id 001-81994, span [19687-19699])\n","Context: he police, which was given on 10 July 1997, was read out and the parties\n","=============\n","Mention: 10 July 1997 (doc_id 001-81994, span [23603-23615])\n","Context: she had told to the police on 10 July 1997 – including about parts of th\n","=============\n","Mention: disqualification (doc_id 001-81994, span [22963-22979])\n","Context:  a result of jury member W.'s disqualification, I have placed decisive empha\n","=============\n","Mention: 28 February 2003 (doc_id 001-81994, span [23355-23371])\n","Context: others before she withdrew on 28 February 2003. I refer to the fact that W. \n","=============\n","Mention: 1997 (doc_id 001-81994, span [19964-19968])\n","Context:  on 10 June [presumably July] 1997. She has not been called as a\n","=============\n","Mention: publish a written apology (doc_id 001-122365, span [3826-3851])\n","Context: m the newspaper’s website and publish a written apology for their rights having been \n","=============\n","Mention: Landesgericht (doc_id 001-69167, span [962-975])\n","Context: the ********* ******** ***** (Landesgericht) opened criminal proceedings \n","=============\n","Mention: Oberlandesgericht (doc_id 001-69167, span [1480-1497])\n","Context: he ********* ***** ** ****** (Oberlandesgericht) requested the Constitutional\n","=============\n","Mention: Poznań District Court (doc_id 001-61739, span [2215-2236])\n","Context: rt fees. On 28 March 1994 the Poznań District Court rejected his application. On \n","=============\n","Mention: District Court (doc_id 001-61739, span [2571-2585])\n","Context:  time. On 8 February 1995 the District Court partly exempted him from the \n","=============\n","Mention: District Court (doc_id 001-61739, span [2648-2662])\n","Context: rt fees. On * ***** **** the District Court held a hearing. On 28 May 199\n","=============\n","Mention: Poznań District Court (doc_id 001-61739, span [3076-3097])\n","Context: laim. On ** ******* **** the Poznań District Court gave judgment. On ** ***** **\n","=============\n","Mention: Poznań District Court (doc_id 001-61739, span [3314-3335])\n","Context: the case. On * **** **** the Poznań District Court gave judgment. On ** ******* \n","=============\n","Mention: District Court (doc_id 001-61739, span [3466-3480])\n","Context: t fees. On 4 January 2001 the District Court rejected his application. On \n","=============\n","Mention: District Court (doc_id 001-61739, span [6317-6331])\n","Context: ******* *****. It ordered the District Court to determine the amount of co\n","=============\n","Mention: District Court (doc_id 001-61739, span [6514-6528])\n","Context: ly. On 28 September 1994 the District Court ordered that an expert opinio\n","=============\n","Mention: District Court (doc_id 001-61739, span [6676-6690])\n","Context: ng judge. On ** **** **** the District Court rejected his challenge as unf\n","=============\n","Mention: District Court (doc_id 001-61739, span [7031-7045])\n","Context: ****. On ** ******* **** the District Court gave judgment. On ** ********\n","=============\n","Mention: Pearman (doc_id 001-161738, span [18882-18889])\n","Context:  fitted the Appellant and not Pearman. Against these, one witness d\n","=============\n","Mention: Pearman (doc_id 001-161738, span [19235-19242])\n","Context:  as the Appellant rather than Pearman. If the Appellant seriously w\n","=============\n","Mention: Pearman (doc_id 001-161738, span [20332-20339])\n","Context: te apart from the evidence of Pearman’s telephone calls, we had no \n","=============\n","Mention: Vectra (doc_id 001-161738, span [19466-19472])\n","Context: t described the driver of the Vectra car, seen by her together wit\n","=============\n","Mention: Vectra (doc_id 001-161738, span [19718-19724])\n","Context: lating to the purchase of the Vectra and the hire of the AVA van o\n","=============\n","Mention: Vectra (doc_id 001-161738, span [20129-20135])\n","Context: ity of the location where the Vectra was set on fire, all powerful\n","=============\n","Mention: AVA (doc_id 001-161738, span [19508-19511])\n","Context: seen by her together with the AVA van, as in his late teens or \n","=============\n","Mention: AVA (doc_id 001-161738, span [19745-19748])\n","Context: he Vectra and the hire of the AVA van on the day of the murder \n","=============\n","Mention: white (doc_id 001-161738, span [18759-18764])\n","Context: ggett described the gunman as white, in his 20s, athletic and abo\n","=============\n","Mention: Seton (doc_id 001-161738, span [19845-19850])\n","Context: he cell phone evidence showed Seton to be in the vicinity of the \n","=============\n","Mention: Seton (doc_id 001-161738, span [20250-20255])\n","Context: n that on a previous occasion Seton had had a connection with a f\n","=============\n","Mention: Miss Wass (doc_id 001-161738, span [18969-18978])\n","Context: as not appearing to be young. Miss Wass suggested that the evidence o\n","=============\n","Mention: Bartlett (doc_id 001-161738, span [18336-18344])\n","Context: ***. He was ** at the date of Bartlett’s murder. The evidence of Rit\n","=============\n","Mention: Bartlett (doc_id 001-161738, span [19959-19967])\n","Context: ast telephone connection with Bartlett, just before the murder, and \n","=============\n","Mention: Rita Willott (doc_id 001-161738, span [18371-18383])\n","Context: ett’s murder. The evidence of Rita Willott (described by the judge as an\n","=============\n","Mention: aged between 20 and 30 (doc_id 001-161738, span [18533-18555])\n","Context: the man who fired the gun was aged between 20 and 30, of average build and height,\n","=============\n","Mention: Jack Doyle (doc_id 001-161738, span [18621-18631])\n","Context: e was wearing a baseball cap. Jack Doyle, a boy aged 10, said that the\n","=============\n","Mention: mid-30s (doc_id 001-161738, span [18711-18718])\n","Context: a baseball cap and was in his mid-30s. Gordon Raggett described the\n","=============\n","Mention: Gordon Raggett (doc_id 001-161738, span [18720-18734])\n","Context: l cap and was in his mid-30s. Gordon Raggett described the gunman as white\n","=============\n","Mention: 20s (doc_id 001-161738, span [18773-18776])\n","Context: d the gunman as white, in his 20s, athletic and about 5 feet 10\n","=============\n","Mention: 5 feet 10 inches (doc_id 001-161738, span [18797-18813])\n","Context: n his 20s, athletic and about 5 feet 10 inches, of slim build. All these des\n","=============\n","Mention: slim build (doc_id 001-161738, span [18818-18828])\n","Context: nd about 5 feet 10 inches, of slim build. All these descriptions fitte\n","=============\n","Mention: Miss Willott (doc_id 001-161738, span [19291-19303])\n","Context: seriously wished to challenge Miss Willott’s evidence, she should have b\n","=============\n","Mention: Kate Botwright (doc_id 001-161738, span [19423-19437])\n","Context: oss examined. (ix) Similarly, Kate Botwright described the driver of the V\n","=============\n","Mention: early 20s (doc_id 001-161738, span [19541-19550])\n","Context:  van, as in his late teens or early 20s, with short brown hair and we\n","=============\n","Mention: 6 March 2010 (doc_id 001-161738, span [20433-20445])\n","Context: iction of the Appellant.” On 6 March 2010 the applicant was informed th\n","=============\n","Mention: 24833/94 (doc_id 001-58910, span [19815-19823])\n","Context: declared the application (no. 24833/94) admissible on 16 April 1996.\n","=============\n","Mention: 16 April 1996 (doc_id 001-58910, span [19839-19852])\n","Context:  (no. 24833/94) admissible on 16 April 1996. In its report of 29 October \n","=============\n","Mention: 29 October 1997 (doc_id 001-58910, span [19871-19886])\n","Context:  April 1996. In its report of 29 October 1997 (former Article 31 of the Con\n","=============\n","Mention: T. (doc_id 001-109575, span [20135-20137])\n","Context:  to the negative reactions of T. and S. before, during and aft\n","=============\n","Mention: S. (doc_id 001-109575, span [20142-20144])\n","Context:  negative reactions of T. and S. before, during and after the \n","=============\n","Mention: three months (doc_id 001-109575, span [9492-9504])\n","Context:  with the children once every three months in a neutral environment wher\n","=============\n","Mention: three months (doc_id 001-109575, span [14944-14956])\n","Context: onth to begin with and, after three months, to spend one weekend a month\n","=============\n","Mention: Mr Androsch (doc_id 001-58087, span [19160-19171])\n","Context:  frequently made reference to Mr Androsch's conviction for having made \n","=============\n","Mention: Mr Androsch (doc_id 001-58087, span [20708-20719])\n","Context: xtent to which the comment on Mr Androsch's defence was capable of infl\n","=============\n","Mention: Mr Androsch (doc_id 001-58087, span [21011-21022])\n","Context: value of the answers given by Mr Androsch, not just – as the court belo\n","=============\n","Mention: Mr Androsch (doc_id 001-58087, span [22859-22870])\n","Context: ng he had been convinced that Mr Androsch had committed tax evasion. In\n","=============\n","Mention: Mr Androsch (doc_id 001-58087, span [22949-22960])\n","Context: ue he had not only criticised Mr Androsch's statement but had also anti\n","=============\n","Mention: Mr Androsch (doc_id 001-58087, span [23567-23578])\n","Context: ny mistakes and not to handle Mr Androsch with kid gloves.”\n","=============\n","Mention: Profil (doc_id 001-58087, span [21579-21585])\n","Context: the lay judges regularly read Profil. On the contrary, in spectacu\n","=============\n","Mention: tax evasion (doc_id 001-58087, span [22885-22896])\n","Context: hat Mr Androsch had committed tax evasion. In the article in issue he h\n","=============\n","Mention: taxes (doc_id 001-58087, span [19030-19035])\n","Context: han that Androsch was evading taxes”, was a quotation from the pu\n","=============\n","Mention: article (doc_id 001-58087, span [21510-21517])\n","Context: fore not be influenced by his article. It was in no way certain tha\n","=============\n","Mention: article (doc_id 001-58087, span [21853-21860])\n","Context: e reading of the incriminated article was capable of influencing th\n","=============\n","Mention: article (doc_id 001-58087, span [22045-22052])\n","Context: e it can be inferred from the article that the accused wished to us\n","=============\n","Mention: article (doc_id 001-58087, span [22641-22648])\n","Context: ssion that he had written the article with the intention of influen\n","=============\n","Mention: article (doc_id 001-58087, span [22905-22912])\n","Context: committed tax evasion. In the article in issue he had not only crit\n","=============\n","Mention: article (doc_id 001-58087, span [23190-23197])\n","Context: tter placed at the top of the article – ‘Above all, there were to b\n","=============\n","Mention: written (doc_id 001-58087, span [22629-22636])\n","Context: ed the impression that he had written the article with the intentio\n","=============\n","Mention: written (doc_id 001-58087, span [22766-22773])\n","Context: o the case since 1978 and had written more than a hundred articles \n","=============\n","Mention: Androsch (doc_id 001-58087, span [19009-19017])\n","Context: ther interpretation than that Androsch was evading taxes”, was a quo\n","=============\n","Mention: Androsch (doc_id 001-58087, span [21451-21459])\n","Context: ng-standing commitment in the Androsch case and would therefore not \n","=============\n","Mention: Mr Heinz Tschernutter (doc_id 001-58087, span [23143-23164])\n","Context: tation of the answer given by Mr Heinz Tschernutter placed at the top of the arti\n","=============\n","Mention: tax (doc_id 001-58087, span [18949-18952])\n","Context: ing money not declared to the tax authorities allows of no othe\n","=============\n","Mention: prohibited influence on criminal proceedings (doc_id 001-58087, span [19426-19470])\n","Context: applicant of having exercised prohibited influence on criminal proceedings and imposed on him forty day-\n","=============\n","Mention: ATS 1,200 (doc_id 001-58087, span [19509-19518])\n","Context: sed on him forty day-fines of ATS 1,200 each, that is ATS 48,000, or \n","=============\n","Mention: ATS 48,000 (doc_id 001-58087, span [19533-19543])\n","Context: es of ATS 1,200 each, that is ATS 48,000, or twenty days' imprisonment\n","=============\n","Mention: 25 March 1993 (doc_id 001-58087, span [19742-19755])\n","Context: as served on the applicant on 25 March 1993. The court held, inter alia:\n","=============\n","Mention: Regional Court (doc_id 001-58087, span [21328-21342])\n","Context:  of Appeal also contested the Regional Court's assumption that everybody, \n","=============\n","Mention: 1978 (doc_id 001-58087, span [22753-22757])\n","Context: esearched into the case since 1978 and had written more than a h\n","=============\n","Mention: hundred articles (doc_id 001-58087, span [22786-22802])\n","Context: 8 and had written more than a hundred articles about it. From the beginning \n","=============\n","Mention: 15088/89 (doc_id 001-57879, span [21232-21240])\n","Context: declared the application (no. 15088/89) admissible on 3 December 199\n","=============\n","Mention: Mr Jacubowski (doc_id 001-57879, span [20951-20964])\n","Context: amage and the distribution of Mr Jacubowski’s circular. PROCEEDINGS BEFOR\n","=============\n","Mention: Mr Jacubowski (doc_id 001-57879, span [21012-21025])\n","Context: EDINGS BEFORE THE COMMISSION Mr Jacubowski applied to the Commission on \n","=============\n","Mention: 11 April 1989 (doc_id 001-57879, span [21055-21068])\n","Context:  applied to the Commission on 11 April 1989. Relying on Article 10 (art. \n","=============\n","Mention: Mr R. Ryssdal (doc_id 001-57879, span [1471-1484])\n","Context: he Convention) (art. 43), and Mr R. Ryssdal, the President of the Court (\n","=============\n","Mention: ddp (doc_id 001-57879, span [19140-19143])\n","Context: ing his relationship with the ddp and ‘current developments at \n","=============\n","Mention: ddp (doc_id 001-57879, span [20389-20392])\n","Context:  which had been issued by the ddp (see paragraph 12 above) did \n","=============\n","Mention: ddp (doc_id 001-57879, span [20700-20703])\n","Context: im for damages brought by the ddp in reliance on the Court of A\n","=============\n","Mention: ddp (doc_id 001-57879, span [20813-20816])\n","Context: h 17 above). It held that the ddp had insufficiently substantia\n","=============\n","Mention: Düsseldorf Regional Court (doc_id 001-57879, span [20629-20654])\n","Context: not. On 30 November 1988 the Düsseldorf Regional Court dismissed a claim for damages\n","=============\n","Mention: 11 December 1986 (doc_id 001-57879, span [20753-20769])\n","Context: Court of Appeal’s judgment of 11 December 1986 (see paragraph 17 above). It \n","=============\n","Mention: 30 November 1988 (doc_id 001-57879, span [20608-20624])\n","Context: pinion, which it was not. On 30 November 1988 the Düsseldorf Regional Court\n","=============\n","Mention: 3 December 1991 (doc_id 001-57879, span [21256-21271])\n","Context:  (no. 15088/89) admissible on 3 December 1991. In its report of 7 January 1\n","=============\n","Mention: 7 January 1993 (doc_id 001-57879, span [21290-21304])\n","Context: cember 1991. In its report of 7 January 1993 (made under Article 31) (art.\n","=============\n","Mention: State Security Court (doc_id 001-83619, span [1979-1999])\n","Context: ****. The single judge of the State Security Court duly extended the custody per\n","=============\n","Mention: Ms C. (doc_id 001-86298, span [20184-20189])\n","Context: y 2004 the Office had granted Ms C. NOK 182,313 in compensation, \n","=============\n","Mention: 27 November 2003 (doc_id 001-86298, span [19502-19518])\n","Context: en the Supreme Court ruled on 27 November 2003 that the presumption of innoc\n","=============\n","Mention: 20 October 2004 (doc_id 001-86298, span [20006-20021])\n","Context: ant has submitted a letter of 20 October 2004 from the Compensation Office \n","=============\n","Mention: 24 May 2004 (doc_id 001-86298, span [20149-20160])\n","Context:  states that by a decision of 24 May 2004 the Office had granted Ms C. \n","=============\n","Mention: NOK 182,313 (doc_id 001-86298, span [20190-20201])\n","Context:  the Office had granted Ms C. NOK 182,313 in compensation, “having foun\n","=============\n","Mention: NOK 124,000 (doc_id 001-86298, span [20450-20461])\n","Context: ice might seek restitution of NOK 124,000 from him.\n","=============\n","Computing evaluation metrics for /content/drive/MyDrive/266 - Natural Language Processing/Final Project/data/tab/echr_longformer_concat_train_mini_mask_masked_spans.json (64 documents)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 64/64 [00:00<00:00, 221.91it/s]\n","100%|██████████| 64/64 [00:00<00:00, 359.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["==> Token-level recall on all identifiers: 0.966\n","==> Token-level recall on all identifiers, factored by type:\n","\tDATETIME:0.988\n","\tCODE:0.981\n","\tORG:0.894\n","\tPERSON:0.981\n","\tDEM:0.917\n","\tLOC:0.997\n","\tQUANTITY:0.964\n","\tMISC:0.950\n","==> Mention-level recall on all identifiers: 0.966\n","==> Entity-level recall on direct identifiers: 0.976\n","==> Entity-level recall on quasi identifiers: 0.976\n","==> Uniform token-level precision on all identifiers: 0.999\n","==> Uniform mention-level precision on all identifiers: 0.999\n"]}],"source":["compute_evaluation_metrics(\n","    gold_standard_file=gold_standard_file_path,\n","    masked_output_files=[masked_output_files_path],\n","    token_weighting=\"uniform\",\n","    only_docs=[],\n","    verbose=True\n",")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpv6eub27FlEwUB3Nx9EGc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}